---
title: "Take a Sad Plot and Make it Better 3.0"
subtitle: "CS631 Final Project Slides"
author: "Kendra Chalkley"
date: "June 18, 2018" 
output: 
  xaringan::moon_reader:
    css: [default, metropolis, metropolis-fonts]
    nature:
        highlightStyle: atelier-lakeside-light
        highlightLines: true
        countIncrementalSlides: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(here) 
library(ggridges)

#Uncomment for Serve Site
#alldicts <- read_csv(here('631FinalProject', 'static','data','redditProject','subset_medoutput.csv'))  
#Uncomment for Infinite Moonreader
alldicts <- read_csv(here('static','data','redditProject','subset_medoutput.csv'))  
nfreqs <- read_csv(here('static','data','redditProject','normal_subset_freqs.csv'))
redfreqs <- read_csv(here('static','data','redditProject','reduced_normal_subset_freqs'))
clusters <- read_csv(here('static','data','redditProject','centers'))

```


---  
# Data

.pull-left[
* Source: Reddit
  + a website www.reddit.com
* `subreddit` /r/ 
  + <=20 character, case sensitive forum name
* `posts` 
  + a count of posts in each subreddit
  + only `self` posts were included in this dataset
  + posts < 100 words in length were filtered out of this dataset
* `wordcount`
  + a sum of the total number of words in all posts in that subreddit
]
--
.pull-right[
* `dictionary` 
  + the name of one of 65 dictionaries
  + 64 from an outdated version of Linguistic Inquiry and Word Count texual analysis software 
  + plus an 'absolutist' dictionary curated by by AlMosaiwi and Johnstone(2018) as described in [In an Absolute State](http://journals.sagepub.com/doi/abs/10.1177/2167702617747074)  
* `freq` the frequency of words from each dictionary $$\frac{number\ of\ words\ matching\ dictionary}{number\ of\ total\ words}$$
]

---
# Data
```{r, message=FALSE}
#filter out mistakes of data collection process and typecast variables
alldicts <- alldicts %>% 
  mutate_at(vars(ends_with('freq')), as.numeric)

#Tidy-ify 
alldictslong <- alldicts %>% 
  gather(key='dictionary',value='freq',-subreddit,-'count(1)',-'sum(wordcount)') %>% 
  select(subreddit,dictionary,freq)%>%   
  mutate_at('dictionary', as.factor) %>% 
  group_by(subreddit) %>% 
  arrange(desc(freq)) 
 
glimpse(alldictslong)
```


---
# Data

```{r}
alldicts %>% 
  arrange(absolutistfreq) %>% 
  glimpse()
```
---
# Machine Learning Techniques
## Principle Component Analysis
* Method of reducing dimensionality
* Effective when features are correlated with each other
* In this case, can explain 90% of variation in dataset in 21 dimensions, or 80% in 11 

## K-means Clustering
* Identifies groups in the data 
* I tried several values of K and am still undecided, but for now, visualizations are given for 11 clusters 
---
# Early Visualization
```{r echo=FALSE, message=FALSE, fig.width=12, fig.height=8}
od_num=65
pc_num=21

correlations <- cor(nfreqs[c(2:(od_num+1))],redfreqs[c(2:(pc_num+1))])

corlong <- melt(correlations ) %>% 
   setNames(c('orig', 'red_dim', 'correlation'))

ggplot(corlong, aes(x=red_dim, y=orig, fill=correlation))+
  geom_tile()+
  theme(axis.text.x = element_text(angle = 60, hjust = 1))+
  scale_fill_distiller(palette = "PRGn")+
  ggtitle('Correlation between PCs and Dictionary Frequency Measures')
```
---

# Audience

1. Myself
1. Linguists
1. Computer scientists
1. Social scientists
1. Others interested in textual analysis, machine learning, and the visualization thereof

---

# Chart Description
* Simple Bar Chart (best for showing relative magnitude)
  + Original features (dictionary frequency) on x axis
  + Magnitude of correlation with principal component on y axis
  + Sorted by correlation between PC and dictionary
* Accompanied by radar chart showing how the components were used to cluster subreddits

---
# Show us the chart already... 

Chart available here: https://kchalk.shinyapps.io/ClustersandCors/

(Or it will be... someday)

---

# An example for grading and stuff: 
```{r}

od_num=65
pc_num=21

corlong <- corlong %>% 
  mutate(dictcat=case_when(
    orig %in% c('ifreq','wefreq','ipronfreq','theyfreq','youfreq','shehefreq','pronounfreq','ppronfreq')
    ~ 'pronons',
    orig %in% c('verbfreq','auxverbfreq','pastfreq','presentfreq','futurefreq')
    ~ 'verbs',
    orig %in% c('articlefreq','adverbfreq','prepsfreq','conjfreq','negatefreq','quantfreq','numberfreq','swearfreq','functfreq')
    ~ 'otherfunctional',
    orig %in% c('socialfreq','familyfreq','friendfreq','humansfreq')
    ~ 'people',
    orig %in% c('affectfreq','posemofreq','negemofreq','anxfreq','angerfreq','sadfreq')
    ~ 'feelings',
    orig %in% c('cogmechfreq','insightfreq','causefreq','discrepfreq','tentatfreq','certainfreq','inhibfreq','inclfreq','exclfreq')
    ~ 'unlabeled',
    orig %in% c('perceptfreq','seefreq','hearfreq','feelfreq')
    ~ 'sense',
    orig %in% c('biofreq','bodyfreq','healthfreq','sexualfreq','ingestfreq')
    ~ 'bio',
    orig %in% c('relativfreq','motionfreq','spacefreq','timefreq')
    ~ 'physics',
    orig %in% c('workfreq','achievefreq','leisurefreq','homefreq','moneyfreq','religfreq','deathfreq')
    ~ 'life',
    orig %in% c('assentfreq','nonflfreq','fillerfreq', 'absolutistfreq')
    ~ 'idk'))
```

---
# An example for grading and stuff (continued): 
```{r}
pcs <- distinct(corlong['red_dim'])
cs <- distinct(clusters['X1'])

pc='d2'
clusterN=1 

radar_color=c("#FF5A5F", "#FFB400", "#007A87",  "#8CE071", "#7B0051", "#00D1C1", "#FFAA91", "#B4A76C", "#9CA299", "#565A5C", "#00A04B", "#E54C20")

workingdf <- corlong %>%  
  filter(red_dim==pc) %>% 
  mutate(poscor=abs(correlation), sign=case_when(correlation>=0~'pos', correlation<0~'neg'))
    
corplot <- ggplot(workingdf, aes(x=fct_reorder(orig,correlation,.desc = TRUE), y=poscor, color=sign, fill=dictcat))+
  geom_col()+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  scale_fill_manual(values=radar_color)+
  scale_color_manual(values=c('black','white'))
    
clusters <- clusters %>%  
  mutate_at(vars(starts_with('d')),rescale)
```
---
# An example for grading and stuff (continued): 

```{r}
clusterplot<- ggradar(clusters[clusterN,], grid.label.size = 5,
        group.point.size = 3,
        axis.label.size = 4,
        legend.text.size = 11,
        group.colours = radar_colour[clusterN])+
  theme(legend.position="bottom") 
```

---
# Correlation plot for PCA 2
```{r fig.width=12, fig.height=8, echo=FALSE}
corplot
```
---

# Radar plot for Cluster 1
```{r fig.width=12, fig.height=8,echo=FALSE}
clusterplot
```



