---
title: 'Graph 5: Finale-- Shiny correlation plus radar'
author: ''
date: '2018-06-14'
slug: graph-5-finale
categories: []
tags: []
description: Desc
hacker_news_id: ''
lobsters_id: ''
meta_img: /images/image.jpg
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) 
#library(ggalt)
library(ggradar)
library(extrafont)
library(ggfortify)
library(infer)
library(forcats)
library(ggridges)
library(here)
library(scales)
library(ggdendro)
library(treemapify)
library(ggplot2)
library(reshape2)
library(knitr)
library(shiny)
library(RColorBrewer)
```


## Preliminaries
### Data

All the graphs of this series are generated from data concerning frequency with which words from assorted dictionaries appear in original reddit posts from various subreddits. 


### Audience


In its current form, audience for this project is almost entirely myself and the professors I'm trying to convince to help me with this project. Eventually I hope to research may be of interest to a larger group, including: 

1. Linguists interested in this method of textual analysis and the language of internet forums
1. Computer sciencists interested in the distributed computing or machine learning that went into this project
1. Social scientists studying any of the many social groups involved on reddit. 

## Plot Type: Bar

### How to read it and what to look for 

### Presentation Tips

### Variations and Alternatives


## Plot Description

### Representaton 

* Simple Bar Chart (best for showing relative magnitude)
  + Original features (dictionary frequency) on x axis
  + Magnitude of correlation with principal component on y axis 
  + Sorted by correlation between PC and dictionary
* Accompanied by radar chart showing how the components were used to cluster subreddits 


<iframe id="example1" src="https://kchalk.shinyapps.io/631Shiny/"
style="border: non; width: 100%; height: 500px"
frameborder="0">
</iframe>

### Methods

```{r}
nfreqs <- read_csv(here('static','data','redditProject','normal_subset_freqs.csv'))
redfreqs <- read_csv(here('static','data','redditProject','reduced_normal_subset_freqs'))

od_num=65
pc_num=21

correlations <- cor(nfreqs[c(2:(od_num+1))],redfreqs[c(2:(pc_num+1))])

corlong <- melt(correlations ) %>% 
   setNames(c('orig', 'red_dim', 'correlation'))


corlong <- corlong %>% 
  mutate(dictcat=case_when(
           orig %in% c('ifreq','wefreq','ipronfreq','theyfreq','youfreq','shehefreq','pronounfreq','ppronfreq')
           ~ 'pronons',
           orig %in% c('verbfreq','auxverbfreq','pastfreq','presentfreq','futurefreq')
           ~ 'verbs',
           orig %in% c('articlefreq','adverbfreq','prepsfreq','conjfreq','negatefreq','quantfreq','numberfreq','swearfreq','functfreq')
           ~ 'otherfunctional',
           orig %in% c('socialfreq','familyfreq','friendfreq','humansfreq')
           ~ 'people',
           orig %in% c('affectfreq','posemofreq','negemofreq','anxfreq','angerfreq','sadfreq')
           ~ 'feelings',
           orig %in% c('cogmechfreq','insightfreq','causefreq','discrepfreq','tentatfreq','certainfreq','inhibfreq','inclfreq','exclfreq')
           ~ 'unlabeled',
           orig %in% c('perceptfreq','seefreq','hearfreq','feelfreq')
           ~ 'sense',
           orig %in% c('biofreq','bodyfreq','healthfreq','sexualfreq','ingestfreq')
           ~ 'bio',
           orig %in% c('relativfreq','motionfreq','spacefreq','timefreq')
           ~ 'physics',
           orig %in% c('workfreq','achievefreq','leisurefreq','homefreq','moneyfreq','religfreq','deathfreq')
           ~ 'life',
           orig %in% c('assentfreq','nonflfreq','fillerfreq', 'absolutistfreq')
           ~ 'idk'))

```


```{r}
clusters <- read_csv(here('static','data','redditProject','centers')) 
```


```{r}
pcs <- distinct(corlong['red_dim'])
cs <- distinct(clusters['X1'])
```

The chart is hosted on [shinyapps.io](https://kchalk.shinyapps.io/631Shiny/) 
<iframe id="example1" src="https://kchalk.shinyapps.io/631Shiny/"
style="border: non; width: 100%; height: 500px"
frameborder="0">
</iframe>