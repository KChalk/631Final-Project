<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Post on CS631: Take a sad plot and make it better</title>
    <link>/post/</link>
    <description>Recent content in Post on CS631: Take a sad plot and make it better</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Wed, 13 Jun 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Graph 4: PCA Correlations </title>
      <link>/post/graph-4-tba/</link>
      <pubDate>Wed, 13 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/graph-4-tba/</guid>
      <description>covariances &amp;lt;- read_csv(here(&amp;#39;static&amp;#39;,&amp;#39;data&amp;#39;,&amp;#39;redditProject&amp;#39;,&amp;#39;subset_covariance.csv&amp;#39;)) ## Warning: Missing column names filled in: &amp;#39;X1&amp;#39; [1] ## Parsed with column specification: ## cols( ## .default = col_double(), ## X1 = col_character() ## ) ## See spec(...) for full column specifications. covlong &amp;lt;- gather(covariances, key=newDimension, value=covariance, -X1) ggplot(covlong, aes(x=newDimension, y=X1, fill=covariance))+ geom_tile()+ theme(axis.text.x = element_text(angle = 60, hjust = 1)) nfreqs &amp;lt;- read_csv(here(&amp;#39;static&amp;#39;,&amp;#39;data&amp;#39;,&amp;#39;redditProject&amp;#39;,&amp;#39;normal_subset_freqs.csv&amp;#39;)) ## Parsed with column specification: ## cols( ## .default = col_double(), ## subreddit = col_character() ## ) ## See spec(.</description>
    </item>
    
    <item>
      <title>Graph 5: Finale-- Radar plus correlation bars</title>
      <link>/post/graph-5-finale/</link>
      <pubDate>Wed, 13 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/graph-5-finale/</guid>
      <description>nfreqs &amp;lt;- read_csv(here(&amp;#39;static&amp;#39;,&amp;#39;data&amp;#39;,&amp;#39;redditProject&amp;#39;,&amp;#39;normal_subset_freqs.csv&amp;#39;)) ## Parsed with column specification: ## cols( ## .default = col_double(), ## subreddit = col_character() ## ) ## See spec(...) for full column specifications. redfreqs &amp;lt;- read_csv(here(&amp;#39;static&amp;#39;,&amp;#39;data&amp;#39;,&amp;#39;redditProject&amp;#39;,&amp;#39;reduced_normal_subset_freqs&amp;#39;)) ## Warning: Missing column names filled in: &amp;#39;X1&amp;#39; [1] ## Parsed with column specification: ## cols( ## .default = col_double(), ## X1 = col_integer() ## ) ## See spec(...) for full column specifications. od_num=65 pc_num=21 correlations &amp;lt;- cor(nfreqs[c(2:(od_num+1))],redfreqs[c(2:(pc_num+1))]) corlong &amp;lt;- melt(correlations ) %&amp;gt;% setNames(c(&amp;#39;orig&amp;#39;, &amp;#39;red_dim&amp;#39;, &amp;#39;correlation&amp;#39;)) corlong &amp;lt;- corlong %&amp;gt;% mutate(dictcat=case_when( orig %in% c(&amp;#39;ifreq&amp;#39;,&amp;#39;wefreq&amp;#39;,&amp;#39;ipronfreq&amp;#39;,&amp;#39;theyfreq&amp;#39;,&amp;#39;youfreq&amp;#39;,&amp;#39;shehefreq&amp;#39;,&amp;#39;pronounfreq&amp;#39;,&amp;#39;ppronfreq&amp;#39;) ~ &amp;#39;pronons&amp;#39;, orig %in% c(&amp;#39;verbfreq&amp;#39;,&amp;#39;auxverbfreq&amp;#39;,&amp;#39;pastfreq&amp;#39;,&amp;#39;presentfreq&amp;#39;,&amp;#39;futurefreq&amp;#39;) ~ &amp;#39;verbs&amp;#39;, orig %in% c(&amp;#39;articlefreq&amp;#39;,&amp;#39;adverbfreq&amp;#39;,&amp;#39;prepsfreq&amp;#39;,&amp;#39;conjfreq&amp;#39;,&amp;#39;negatefreq&amp;#39;,&amp;#39;quantfreq&amp;#39;,&amp;#39;numberfreq&amp;#39;,&amp;#39;swearfreq&amp;#39;,&amp;#39;functfreq&amp;#39;) ~ &amp;#39;otherfunctional&amp;#39;, orig %in% c(&amp;#39;socialfreq&amp;#39;,&amp;#39;familyfreq&amp;#39;,&amp;#39;friendfreq&amp;#39;,&amp;#39;humansfreq&amp;#39;) ~ &amp;#39;people&amp;#39;, orig %in% c(&amp;#39;affectfreq&amp;#39;,&amp;#39;posemofreq&amp;#39;,&amp;#39;negemofreq&amp;#39;,&amp;#39;anxfreq&amp;#39;,&amp;#39;angerfreq&amp;#39;,&amp;#39;sadfreq&amp;#39;) ~ &amp;#39;feelings&amp;#39;, orig %in% c(&amp;#39;cogmechfreq&amp;#39;,&amp;#39;insightfreq&amp;#39;,&amp;#39;causefreq&amp;#39;,&amp;#39;discrepfreq&amp;#39;,&amp;#39;tentatfreq&amp;#39;,&amp;#39;certainfreq&amp;#39;,&amp;#39;inhibfreq&amp;#39;,&amp;#39;inclfreq&amp;#39;,&amp;#39;exclfreq&amp;#39;) ~ &amp;#39;unlabeled&amp;#39;, orig %in% c(&amp;#39;perceptfreq&amp;#39;,&amp;#39;seefreq&amp;#39;,&amp;#39;hearfreq&amp;#39;,&amp;#39;feelfreq&amp;#39;) ~ &amp;#39;sense&amp;#39;, orig %in% c(&amp;#39;biofreq&amp;#39;,&amp;#39;bodyfreq&amp;#39;,&amp;#39;healthfreq&amp;#39;,&amp;#39;sexualfreq&amp;#39;,&amp;#39;ingestfreq&amp;#39;) ~ &amp;#39;bio&amp;#39;, orig %in% c(&amp;#39;relativfreq&amp;#39;,&amp;#39;motionfreq&amp;#39;,&amp;#39;spacefreq&amp;#39;,&amp;#39;timefreq&amp;#39;) ~ &amp;#39;physics&amp;#39;, orig %in% c(&amp;#39;workfreq&amp;#39;,&amp;#39;achievefreq&amp;#39;,&amp;#39;leisurefreq&amp;#39;,&amp;#39;homefreq&amp;#39;,&amp;#39;moneyfreq&amp;#39;,&amp;#39;religfreq&amp;#39;,&amp;#39;deathfreq&amp;#39;) ~ &amp;#39;life&amp;#39;, orig %in% c(&amp;#39;assentfreq&amp;#39;,&amp;#39;nonflfreq&amp;#39;,&amp;#39;fillerfreq&amp;#39;, &amp;#39;absolutistfreq&amp;#39;) ~ &amp;#39;idk&amp;#39;)) clusters &amp;lt;- read_csv(here(&amp;#39;static&amp;#39;,&amp;#39;data&amp;#39;,&amp;#39;redditProject&amp;#39;,&amp;#39;centers&amp;#39;))  ## Warning: Missing column names filled in: &amp;#39;X1&amp;#39; [1] ## Parsed with column specification: ## cols( ## .</description>
    </item>
    
    <item>
      <title>Graph 3: Radar</title>
      <link>/post/graph-3-tba/</link>
      <pubDate>Tue, 12 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/graph-3-tba/</guid>
      <description>alldicts &amp;lt;- read_csv(here(&amp;#39;static&amp;#39;,&amp;#39;data&amp;#39;,&amp;#39;redditProject&amp;#39;,&amp;#39;medoutput.csv&amp;#39;)) ## Parsed with column specification: ## cols( ## .default = col_double(), ## subreddit = col_character(), ## `count(1)` = col_integer(), ## `sum(wordcount)` = col_integer() ## ) ## See spec(...) for full column specifications. alldicts &amp;lt;- alldicts %&amp;gt;% filter(subreddit!=&amp;#39;subreddit&amp;#39; &amp;amp; subreddit!=&amp;#39;TypeError&amp;#39;) %&amp;gt;% mutate_at(vars(ends_with(&amp;#39;freq&amp;#39;)), as.numeric) alldictslong &amp;lt;- alldicts %&amp;gt;% gather(key=&amp;#39;dictionary&amp;#39;,value=&amp;#39;freq&amp;#39;,-subreddit,-&amp;#39;count(1)&amp;#39;,-&amp;#39;sum(wordcount)&amp;#39;) %&amp;gt;% select(subreddit,dictionary,freq)%&amp;gt;% mutate_at(&amp;#39;dictionary&amp;#39;, as.factor) %&amp;gt;% group_by(subreddit)  normalit&amp;lt;-function(m){ (m - min(m))/(max(m)-min(m)) } dictsubset=c(&amp;#39;absolutistfreq&amp;#39;,&amp;#39;pronounfreq&amp;#39;,&amp;#39;socialfreq&amp;#39;,&amp;#39;perceptfreq&amp;#39;,&amp;#39;sadfreq&amp;#39;) ofinterestplus=c(&amp;#39;SuicideWatch&amp;#39;, &amp;#39;Anxiety&amp;#39;,&amp;#39;depression&amp;#39;, &amp;#39;raisedbynarcissists&amp;#39;,&amp;#39;trees&amp;#39;,&amp;#39;gaybros&amp;#39;,&amp;#39;TwoXChromosomes&amp;#39;) alldictslong %&amp;gt;% filter(subreddit %in% ofinterestplus) %&amp;gt;% filter(dictionary %in% dictsubset | dictcat==&amp;#39;feelings&amp;#39;) %&amp;gt;% select(&amp;#39;subreddit&amp;#39;, &amp;#39;freq&amp;#39;,&amp;#39;dictionary&amp;#39;) %&amp;gt;% spread(dictionary,freq)-&amp;gt; alldictsradar ggradar(alldictsradar,grid.</description>
    </item>
    
    <item>
      <title>Graph 2 Raincloud</title>
      <link>/post/2018-06-11-graph-2-raincloud/</link>
      <pubDate>Mon, 11 Jun 2018 10:29:07 -0700</pubDate>
      
      <guid>/post/2018-06-11-graph-2-raincloud/</guid>
      <description>Graph 2 Dictionary Rain cloud Data The first two graphs of this series are generated from data concerning frequency with which words from assorted dictionaries appear in original reddit posts from various subreddits. For the second of these graphs, I’m using a dataset called alldicts (in its long form: alldictslong) which includes many of the same columns as allsubs, including absoltist frequecies of absolutist words as well as frequencies of words in 64 other dictinoaries:</description>
    </item>
    
    <item>
      <title>Graph 1 Subreddit Scatter</title>
      <link>/post/2018-06-10-graph-1-subreddit-scatter/</link>
      <pubDate>Sun, 10 Jun 2018 15:50:12 -0700</pubDate>
      
      <guid>/post/2018-06-10-graph-1-subreddit-scatter/</guid>
      <description>Graph 1 Subreddit Scatter Data The first two graphs of this series are generated from data concerning frequency with which words from assorted dictionaries appear in original reddit posts from various subreddits.
The first dataset, called allsubs includes 5 columns :
subreddit the name of one of ~120k subreddits posts a count of (qualifying) posts in each subreddit wordcount a sum of the total number of words in all posts in that subreddit abscount a sum of the total number of ‘absolutist’ words in posts</description>
    </item>
    
  </channel>
</rss>