<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Post on CS631: Take a sad plot and make it better</title>
    <link>/post/</link>
    <description>Recent content in Post on CS631: Take a sad plot and make it better</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Thu, 14 Jun 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Graph 5: Finale-- Shiny correlation plus radar</title>
      <link>/post/graph-5-finale/</link>
      <pubDate>Thu, 14 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/graph-5-finale/</guid>
      <description>Preliminaries Data All the graphs of this series are generated from data concerning frequency with which words from assorted dictionaries appear in original reddit posts from various subreddits.
 Audience In its current form, audience for this project is almost entirely myself and the professors I’m trying to convince to help me with this project. Eventually I hope to research may be of interest to a larger group, including:
Linguists interested in this method of textual analysis and the language of internet forums Computer sciencists interested in the distributed computing or machine learning that went into this project Social scientists studying any of the many social groups involved on reddit.</description>
    </item>
    
    <item>
      <title>Graph 4: Radar</title>
      <link>/post/graph-3-tba/</link>
      <pubDate>Wed, 13 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/graph-3-tba/</guid>
      <description>Preliminaries Data All the graphs of this series are generated from data concerning frequency with which words from assorted dictionaries appear in original reddit posts from various subreddits. This graph shows clusters centers generated by running K means clustering (K=7) on the data shown in alldicts in graph 2, after reducing its dimensionality through prinicipal component analyis to the 21 dimensions shown in graph 3
## Warning: Missing column names filled in: &amp;#39;X1&amp;#39; [1] ## Parsed with column specification: ## cols( ## .</description>
    </item>
    
    <item>
      <title>Graph 3: PCA Correlations </title>
      <link>/post/graph-4-tba/</link>
      <pubDate>Tue, 12 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/graph-4-tba/</guid>
      <description>Preliminaries  Data All the graphs of this series are generated from data concerning frequency with which words from assorted dictionaries appear in original reddit posts from various subreddits.
Because alldicts is of such high dimensionality– 65 is a lot of features to keep track of– I ran principle component analysis (PCA) on the data to reduce the dimensionality to 21 features, while still explaining 90% of the variance within the dataset.</description>
    </item>
    
    <item>
      <title>Graph 2 Raincloud</title>
      <link>/post/2018-06-11-graph-2-raincloud/</link>
      <pubDate>Mon, 11 Jun 2018 10:29:07 -0700</pubDate>
      
      <guid>/post/2018-06-11-graph-2-raincloud/</guid>
      <description>Data All the graph in this series are generated from data concerning frequency with which words from assorted dictionaries appear in original reddit posts from various subreddits. For the second of these graphs, I’m using a dataset called alldicts (in its long form: alldictslong) which includes many of the same columns as allsubs, including absoltist frequecies of absolutist words as well as frequencies of words in 64 other dictinoaries:
subreddit the name of one of 29 subreddits (a somewhat arbitrarily collected subset of the 120k subreddits in the previous datset) posts a count of qualifying posts in each subreddit wordcount a sum of the total number of words in all posts in that subreddit dictionary the name of one of 65 dictionaries– 64 from an outdated version of LIWC plus the absolutis dictionary mentioned above.</description>
    </item>
    
    <item>
      <title>Graph 1 Subreddit Scatter</title>
      <link>/post/2018-06-10-graph-1-subreddit-scatter/</link>
      <pubDate>Sun, 10 Jun 2018 15:50:12 -0700</pubDate>
      
      <guid>/post/2018-06-10-graph-1-subreddit-scatter/</guid>
      <description>Graph 1 Subreddit Scatter Data All the graphs of this series are generated from data concerning frequency with which words from assorted dictionaries appear in original reddit posts from various subreddits.
The first dataset, called allsubs includes 5 columns :
subreddit the name of one of ~120k subreddits posts a count of (qualifying) posts in each subreddit wordcount a sum of the total number of words in all posts in that subreddit abscount a sum of the total number of ‘absolutist’ words in posts</description>
    </item>
    
  </channel>
</rss>