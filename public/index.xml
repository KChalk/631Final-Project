<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CS631: Take a sad plot and make it better</title>
    <link>/</link>
    <description>Recent content on CS631: Take a sad plot and make it better</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Wed, 13 Jun 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Graph 4: TBA </title>
      <link>/post/graph-4-tba/</link>
      <pubDate>Wed, 13 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/graph-4-tba/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Graph 5: Finale</title>
      <link>/post/graph-5-finale/</link>
      <pubDate>Wed, 13 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/graph-5-finale/</guid>
      <description>radar_colour=rep(c(&amp;quot;#FF5A5F&amp;quot;, &amp;quot;#FFB400&amp;quot;, &amp;quot;#007A87&amp;quot;, &amp;quot;#8CE071&amp;quot;, &amp;quot;#7B0051&amp;quot;, &amp;quot;#00D1C1&amp;quot;, &amp;quot;#FFAA91&amp;quot;, &amp;quot;#B4A76C&amp;quot;, &amp;quot;#9CA299&amp;quot;, &amp;quot;#565A5C&amp;quot;, &amp;quot;#00A04B&amp;quot;, &amp;quot;#E54C20&amp;quot;), 100) clusters &amp;lt;- read_csv(here(&amp;#39;static&amp;#39;,&amp;#39;data&amp;#39;,&amp;#39;redditProject&amp;#39;,&amp;#39;centers&amp;#39;)) ## Warning: Missing column names filled in: &amp;#39;X1&amp;#39; [1] ## Parsed with column specification: ## cols( ## X1 = col_character(), ## d1 = col_double(), ## d2 = col_double(), ## d3 = col_double(), ## d4 = col_double(), ## d5 = col_double(), ## d6 = col_double(), ## d7 = col_double(), ## d8 = col_double(), ## d9 = col_double(), ## d10 = col_double(), ## d11 = col_double() ## ) clusters &amp;lt;- clusters %&amp;gt;% mutate_at(vars(starts_with(&amp;#39;d&amp;#39;)),rescale) clusters ## # A tibble: 7 x 12 ## X1 d1 d2 d3 d4 d5 d6 d7 d8 d9 d10 ## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; ## 1 [&amp;#39;btc&amp;#39;,… 0.</description>
    </item>
    
    <item>
      <title>Graph 3: Radar</title>
      <link>/post/graph-3-tba/</link>
      <pubDate>Tue, 12 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/graph-3-tba/</guid>
      <description>alldicts &amp;lt;- read_csv(here(&amp;#39;static&amp;#39;,&amp;#39;data&amp;#39;,&amp;#39;redditProject&amp;#39;,&amp;#39;medoutput.csv&amp;#39;)) ## Parsed with column specification: ## cols( ## .default = col_double(), ## subreddit = col_character(), ## `count(1)` = col_integer(), ## `sum(wordcount)` = col_integer() ## ) ## See spec(...) for full column specifications. alldicts &amp;lt;- alldicts %&amp;gt;% filter(subreddit!=&amp;#39;subreddit&amp;#39; &amp;amp; subreddit!=&amp;#39;TypeError&amp;#39;) %&amp;gt;% mutate_at(vars(ends_with(&amp;#39;freq&amp;#39;)), as.numeric) alldictslong &amp;lt;- alldicts %&amp;gt;% gather(key=&amp;#39;dictionary&amp;#39;,value=&amp;#39;freq&amp;#39;,-subreddit,-&amp;#39;count(1)&amp;#39;,-&amp;#39;sum(wordcount)&amp;#39;) %&amp;gt;% select(subreddit,dictionary,freq)%&amp;gt;% mutate_at(&amp;#39;dictionary&amp;#39;, as.factor) %&amp;gt;% group_by(subreddit)  normalit&amp;lt;-function(m){ (m - min(m))/(max(m)-min(m)) } dictsubset=c(&amp;#39;absolutistfreq&amp;#39;,&amp;#39;pronounfreq&amp;#39;,&amp;#39;socialfreq&amp;#39;,&amp;#39;perceptfreq&amp;#39;,&amp;#39;sadfreq&amp;#39;) ofinterestplus=c(&amp;#39;SuicideWatch&amp;#39;, &amp;#39;Anxiety&amp;#39;,&amp;#39;depression&amp;#39;, &amp;#39;raisedbynarcissists&amp;#39;,&amp;#39;trees&amp;#39;,&amp;#39;gaybros&amp;#39;,&amp;#39;TwoXChromosomes&amp;#39;) alldictslong %&amp;gt;% filter(subreddit %in% ofinterestplus) %&amp;gt;% filter(dictionary %in% dictsubset | dictcat==&amp;#39;feelings&amp;#39;) %&amp;gt;% select(&amp;#39;subreddit&amp;#39;, &amp;#39;freq&amp;#39;,&amp;#39;dictionary&amp;#39;) %&amp;gt;% spread(dictionary,freq)-&amp;gt; alldictsradar ggradar(alldictsradar,grid.</description>
    </item>
    
    <item>
      <title>Graph 2 Raincloud</title>
      <link>/post/2018-06-11-graph-2-raincloud/</link>
      <pubDate>Mon, 11 Jun 2018 10:29:07 -0700</pubDate>
      
      <guid>/post/2018-06-11-graph-2-raincloud/</guid>
      <description>Graph 2 Dictionary Rain cloud Data The first two graphs of this series are generated from data concerning frequency with which words from assorted dictionaries appear in original reddit posts from various subreddits. For the second of these graphs, I’m using a dataset called alldicts (in its long form: alldictslong) which includes many of the same columns as allsubs, including absoltist frequecies of absolutist words as well as frequencies of words in 64 other dictinoaries:</description>
    </item>
    
    <item>
      <title>Graph 1 Subreddit Scatter</title>
      <link>/post/2018-06-10-graph-1-subreddit-scatter/</link>
      <pubDate>Sun, 10 Jun 2018 15:50:12 -0700</pubDate>
      
      <guid>/post/2018-06-10-graph-1-subreddit-scatter/</guid>
      <description>Graph 1 Subreddit Scatter Data The first two graphs of this series are generated from data concerning frequency with which words from assorted dictionaries appear in original reddit posts from various subreddits.
The first dataset, called allsubs includes 5 columns :
subreddit the name of one of ~120k subreddits posts a count of (qualifying) posts in each subreddit wordcount a sum of the total number of words in all posts in that subreddit abscount a sum of the total number of ‘absolutist’ words in posts</description>
    </item>
    
    <item>
      <title>About</title>
      <link>/about/</link>
      <pubDate>Thu, 31 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/about/</guid>
      <description>About KChalk
I am a full time graduate student at Oregon Health and Science University (OHSU) in the CS masters program taught by OHSU&amp;rsquo;s Center for Spoken Language Understanding. My undergraduate degree was a BA Linguistics from Reed College. I&amp;rsquo;m currently focusing on computational and medical applications of linguistics to amplify the impact my studies of the field might have on academic and society.
About OHSU&amp;rsquo;s CS631 DataVis
This site has been constructed as an assignment for OHSU&amp;rsquo;s CS 631 Principles and Practices of Data Viualization.</description>
    </item>
    
    <item>
      <title>Home</title>
      <link>/home/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/home/</guid>
      <description>Hey! Welcome to the Kendra&amp;rsquo;s test website. Most content is still default from the cocoa theme.
This page is deployed from my git repository here: https://github.com/KChalk/631Final-Project</description>
    </item>
    
    <item>
      <title>License</title>
      <link>/license/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/license/</guid>
      <description>You can use this page to put a license on the contents of your blog, like so:
 The MIT License (MIT)
Copyright &amp;copy; 2015 Nishanth Shanmughamnishanth.gerrard@gmail.com
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the &amp;ldquo;Software&amp;rdquo;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</description>
    </item>
    
  </channel>
</rss>