<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CS631: Take a sad plot and make it better</title>
    <link>/</link>
    <description>Recent content on CS631: Take a sad plot and make it better</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Thu, 14 Jun 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Graph 5: Finale-- Shiny correlation plus radar</title>
      <link>/post/graph-5-finale/</link>
      <pubDate>Thu, 14 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/graph-5-finale/</guid>
      <description>Preliminaries Data All the graphs of this series are generated from data concerning frequency with which words from assorted dictionaries appear in original reddit posts from various subreddits.
 Audience In its current form, audience for this project is almost entirely myself and the professors I’m trying to convince to help me with this project. Eventually I hope to research may be of interest to a larger group, including:
Linguists interested in this method of textual analysis and the language of internet forums Computer sciencists interested in the distributed computing or machine learning that went into this project Social scientists studying any of the many social groups involved on reddit.</description>
    </item>
    
    <item>
      <title>Graph 4: Radar</title>
      <link>/post/graph-3-tba/</link>
      <pubDate>Wed, 13 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/graph-3-tba/</guid>
      <description>Preliminaries Data All the graphs of this series are generated from data concerning frequency with which words from assorted dictionaries appear in original reddit posts from various subreddits. This graph shows clusters centers generated by running K means clustering (K=7) on the data shown in alldicts in graph 2, after reducing its dimensionality through prinicipal component analyis to the 21 dimensions shown in graph 3
## Warning: Missing column names filled in: &amp;#39;X1&amp;#39; [1] ## Parsed with column specification: ## cols( ## .</description>
    </item>
    
    <item>
      <title>Graph 3: PCA Correlations </title>
      <link>/post/graph-4-tba/</link>
      <pubDate>Tue, 12 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/graph-4-tba/</guid>
      <description>Preliminaries  Data All the graphs of this series are generated from data concerning frequency with which words from assorted dictionaries appear in original reddit posts from various subreddits.
Because alldicts is of such high dimensionality– 65 is a lot of features to keep track of– I ran principle component analysis (PCA) on the data to reduce the dimensionality to 21 features, while still explaining 90% of the variance within the dataset.</description>
    </item>
    
    <item>
      <title>Graph 2 Raincloud</title>
      <link>/post/2018-06-11-graph-2-raincloud/</link>
      <pubDate>Mon, 11 Jun 2018 10:29:07 -0700</pubDate>
      
      <guid>/post/2018-06-11-graph-2-raincloud/</guid>
      <description>Data All the graph in this series are generated from data concerning frequency with which words from assorted dictionaries appear in original reddit posts from various subreddits. For the second of these graphs, I’m using a dataset called alldicts (in its long form: alldictslong) which includes many of the same columns as allsubs, including absoltist frequecies of absolutist words as well as frequencies of words in 64 other dictinoaries:
subreddit the name of one of 29 subreddits (a somewhat arbitrarily collected subset of the 120k subreddits in the previous datset) posts a count of qualifying posts in each subreddit wordcount a sum of the total number of words in all posts in that subreddit dictionary the name of one of 65 dictionaries– 64 from an outdated version of LIWC plus the absolutis dictionary mentioned above.</description>
    </item>
    
    <item>
      <title>Graph 1 Subreddit Scatter</title>
      <link>/post/2018-06-10-graph-1-subreddit-scatter/</link>
      <pubDate>Sun, 10 Jun 2018 15:50:12 -0700</pubDate>
      
      <guid>/post/2018-06-10-graph-1-subreddit-scatter/</guid>
      <description>Graph 1 Subreddit Scatter Data All the graphs of this series are generated from data concerning frequency with which words from assorted dictionaries appear in original reddit posts from various subreddits.
The first dataset, called allsubs includes 5 columns :
subreddit the name of one of ~120k subreddits posts a count of (qualifying) posts in each subreddit wordcount a sum of the total number of words in all posts in that subreddit abscount a sum of the total number of ‘absolutist’ words in posts</description>
    </item>
    
    <item>
      <title>About</title>
      <link>/about/</link>
      <pubDate>Thu, 31 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/about/</guid>
      <description>About KChalk
I am a full time graduate student at Oregon Health and Science University (OHSU) in the CS masters program taught by OHSU&amp;rsquo;s Center for Spoken Language Understanding. My undergraduate degree was a BA Linguistics from Reed College. I&amp;rsquo;m currently focusing on computational and medical applications of linguistics to amplify the impact my studies of the field might have on academic and society.
About OHSU&amp;rsquo;s CS631 DataVis
This site has been constructed as an assignment for OHSU&amp;rsquo;s CS 631 Principles and Practices of Data Viualization.</description>
    </item>
    
    <item>
      <title>Home</title>
      <link>/home/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/home/</guid>
      <description>Hello and welcome to my website hosting final posts and slides for OHSU&amp;rsquo;s CS 631: Principles and Practices of Data Visualization. For more information about me, OHSU, or this class, see my about page. The posts section contains 5 briefs on graphs made for this course. Slides for my final presentation can be found here.
This page is deployed from my git repository here: https://github.com/KChalk/631Final-Project
 </description>
    </item>
    
    <item>
      <title>License</title>
      <link>/license/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/license/</guid>
      <description>You can use this page to put a license on the contents of your blog, like so:
 The MIT License (MIT)
Copyright &amp;copy; 2015 Nishanth Shanmughamnishanth.gerrard@gmail.com
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the &amp;ldquo;Software&amp;rdquo;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</description>
    </item>
    
  </channel>
</rss>